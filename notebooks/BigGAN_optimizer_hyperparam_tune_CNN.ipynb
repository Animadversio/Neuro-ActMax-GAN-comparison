{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from circuit_toolkit.layer_hook_utils import featureFetcher, featureFetcher_module\n",
    "from circuit_toolkit.dataset_utils import create_imagenet_valid_dataset\n",
    "from circuit_toolkit.plot_utils import to_imgrid, show_imgrid, saveallforms, save_imgrid\n",
    "from circuit_toolkit.GAN_utils import upconvGAN, Caffenet, RGB_mean\n",
    "from circuit_toolkit.Optimizers import CholeskyCMAES, CholeskyCMAES_torch, CholeskyCMAES_torch_noCMA\n",
    "from circuit_toolkit.CNN_scorers import TorchScorer, resize_and_pad, resize_and_pad_tsr\n",
    "import torchvision\n",
    "\n",
    "RGB_mean = torch.tensor([0.485, 0.456, 0.406]) #.view(1,-1,1,1).cuda()\n",
    "RGB_std  = torch.tensor([0.229, 0.224, 0.225]) #.view(1,-1,1,1).cuda()\n",
    "IN_transform = torchvision.transforms.Compose([\n",
    "                                            # torchvision.transforms.Resize(256, ),\n",
    "                                            # torchvision.transforms.CenterCrop((256, 256), ),\n",
    "                                            torchvision.transforms.Normalize(RGB_mean, RGB_std)])\n",
    "\n",
    "\n",
    "def optimize_gan_codes(G, CNN, fetcher, unit_idx, imgsize=(256, 256), corner=(0, 0), \n",
    "                      total_steps=100, print_freq=10, RFresize=True,\n",
    "                      init_code_std=0.01, init_sigma=0.06, optimizer=None):\n",
    "    \"\"\"\n",
    "    Optimize GAN codes to maximize activation of a specific CNN unit\n",
    "    \n",
    "    Args:\n",
    "        G: GAN model wrapper with visualize() method\n",
    "        CNN: CNN model to optimize against\n",
    "        unit_idx: Index of unit to optimize\n",
    "        layerkey: Layer name to extract features from\n",
    "        imgsize: Size to resize images to\n",
    "        corner: Corner position for resizing\n",
    "        total_steps: Number of optimization steps\n",
    "        print_freq: How often to print progress\n",
    "        RFresize: Whether to resize images\n",
    "        init_code_std: Standard deviation for initial codes\n",
    "        init_sigma: Initial sigma for optimizer\n",
    "        optimizer: Optional pre-configured optimizer\n",
    "        \n",
    "    Returns:\n",
    "        dict containing optimization results\n",
    "    \"\"\"\n",
    "    code_len = G.codelen  # Fixed for BigGAN\n",
    "    latent_shape = G.latent_shape\n",
    "    \n",
    "    assert not np.isnan(init_sigma)\n",
    "    if optimizer is None:\n",
    "        optimizer = CholeskyCMAES_torch_noCMA(code_len, init_sigma=init_sigma, \n",
    "                                            Aupdate_freq=1000, device='cuda')\n",
    "    \n",
    "    new_codes = init_code_std * torch.randn(1, code_len, device='cuda')\n",
    "    scores_all = []\n",
    "    generations = []\n",
    "    codes_all = []\n",
    "    best_imgs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(total_steps,):\n",
    "            codes_all.append(new_codes.cpu().numpy())\n",
    "            latent_code = new_codes.view(-1, *latent_shape)\n",
    "            imgs = G.visualize(latent_code)\n",
    "            \n",
    "            if RFresize:\n",
    "                imgs = resize_and_pad_tsr(imgs, imgsize, corner, canvas_size=imgsize)\n",
    "                \n",
    "            imgs_pp = IN_transform(imgs)\n",
    "            CNN.model(imgs_pp)\n",
    "            activations = fetcher[\"score\"]\n",
    "            \n",
    "            if activations.ndim == 2:\n",
    "                scores = activations[:, unit_idx]\n",
    "            elif activations.ndim == 4:\n",
    "                center_idx = tuple(dim // 2 for dim in activations.shape[-2:])\n",
    "                scores = activations[:, unit_idx, center_idx[0], center_idx[1]]\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported activation dimension: {activations.ndim}\")\n",
    "                \n",
    "            if i % print_freq == 0 or i == total_steps - 1:\n",
    "                print(\"step %d score %.3f (%.3f) (norm %.2f )\" % (\n",
    "                    i, scores.mean().cpu(), scores.std().cpu(), \n",
    "                    latent_code.view(-1, code_len).norm(dim=1).mean().cpu(),))\n",
    "                    \n",
    "            new_codes = optimizer.step_simple(scores, new_codes, verbosity=False)\n",
    "            scores_all.extend(list(scores.cpu().numpy()))\n",
    "            generations.extend([i] * len(scores))\n",
    "            best_imgs.append(imgs[scores.argmax(),:,:,:].cpu())\n",
    "    \n",
    "    scores_all = np.array(scores_all)\n",
    "    generations = np.array(generations)\n",
    "    codes_all = np.concatenate(codes_all, axis=0)\n",
    "    return {\n",
    "        'scores': scores_all,\n",
    "        'generations': generations, \n",
    "        'codes': codes_all,\n",
    "        'best_imgs': best_imgs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_best_images_traj(results):\n",
    "    # Visualize best images grid\n",
    "    mtg = to_imgrid(results['best_imgs'], nrow=10)\n",
    "    figh = plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mtg)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return figh, mtg\n",
    "\n",
    "\n",
    "def plot_evolution_traj(results):\n",
    "    # Plot evolution trajectory\n",
    "    figh = plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(results['generations'], results['scores'], s=25, alpha=0.5)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "    return figh\n",
    "\n",
    "\n",
    "class BigGAN_EcoSet_Wrapper(nn.Module):\n",
    "    def __init__(self, G, ):\n",
    "        super().__init__()\n",
    "        self.G = G\n",
    "        self.latent_shape = (140 + 128, )\n",
    "        self.codelen = 140 + 128\n",
    "    \n",
    "    def visualize(self, latent_codes):\n",
    "        ys = latent_codes[:, :128]\n",
    "        zs = latent_codes[:, 128:]\n",
    "        imgs = self.G.forward(zs, ys)\n",
    "        imgs = (imgs + 1) / 2\n",
    "        return imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ponce\\.conda\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ponce\\.conda\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BigGAN_wrapper' object has no attribute 'codelen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_87404\\1762888358.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0minit_sigma\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.04\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.06\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.08\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mT0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mEvol_results_INet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize_gan_codes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_IN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetcher\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munit_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_code_std\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_sigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.06\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m                 \u001b[0mT1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"INet x ResNet50-linf8 {layername} ch{unit_i} rep{rep} CMA init sigma {init_sigma}: Act {Evol_results_INet['scores'][-25:].mean():.2f} time {T1-T0:.2f} sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_87404\\1182872251.py\u001b[0m in \u001b[0;36moptimize_gan_codes\u001b[1;34m(G, CNN, fetcher, unit_idx, imgsize, corner, total_steps, print_freq, RFresize, init_code_std, init_sigma, optimizer)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mdict\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0moptimization\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \"\"\"\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mcode_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodelen\u001b[0m  \u001b[1;31m# Fixed for BigGAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mlatent_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BigGAN_wrapper' object has no attribute 'codelen'"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "# sys.path.append(\"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/biggan-pytorch-ecoset/code\")\n",
    "# from BigGAN_nodist import Generator\n",
    "from circuit_toolkit.GAN_utils import upconvGAN, BigGAN_wrapper\n",
    "from pytorch_pretrained_biggan import BigGAN\n",
    "\n",
    "# BGEco_root = \"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/biggan-pytorch-ecoset\"\n",
    "# suffix = \"best2\"\n",
    "# config = torch.load(join(BGEco_root, \"weights\", f\"state_dict_{suffix}.pth\"))['config']\n",
    "# weights_dict = torch.load(join(BGEco_root, \"weights\", f\"G_{suffix}.pth\"))\n",
    "# G = Generator(**config)\n",
    "# G.load_state_dict(weights_dict, strict=True)\n",
    "# G.to(\"cuda\").eval()\n",
    "# G.requires_grad_(False);\n",
    "# G_Eco = BigGAN_EcoSet_Wrapper(G,)\n",
    "\n",
    "\n",
    "BG = BigGAN.from_pretrained(\"biggan-deep-256\")\n",
    "BG.to(\"cuda\").eval()\n",
    "BG.requires_grad_(False);\n",
    "G_IN = BigGAN_wrapper(BG)\n",
    "\n",
    "\n",
    "saveroot = \"F:\\insilico_exps\\BigGAN_hyperparam_tune\"\n",
    "savedir = join(saveroot, \"resnet50_linf8\")\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "CNN = TorchScorer(\"resnet50_linf8\", )\n",
    "for rep in range(3):\n",
    "    for target_module, layername in [\n",
    "        (CNN.model.fc, \"fc\"), \n",
    "        (CNN.model.layer4, \"layer4\"),\n",
    "        (CNN.model.layer3, \"layer3\"),\n",
    "    ]:\n",
    "        fetcher = featureFetcher_module()\n",
    "        fetcher.record_module(target_module, target_name=\"score\")\n",
    "        for unit_i in range(10):\n",
    "            for init_sigma in [0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 0.2, 0.4, 0.8, 1.0, 2.0, 3.0]:\n",
    "                T0 = time.time()\n",
    "                Evol_results_INet = optimize_gan_codes(G_IN, CNN, fetcher, unit_idx=unit_i, init_code_std=0.01, init_sigma=0.06, print_freq=100)\n",
    "                T1 = time.time()\n",
    "                print(f\"INet x ResNet50-linf8 {layername} ch{unit_i} rep{rep} CMA init sigma {init_sigma}: Act {Evol_results_INet['scores'][-25:].mean():.2f} time {T1-T0:.2f} sec\")\n",
    "                # Evol_results_eco = optimize_gan_codes(G_Eco, CNN, fetcher, unit_idx=unit_i, init_code_std=0.01, init_sigma=0.06, print_freq=100)\n",
    "                # T2 = time.time()\n",
    "                # print(f\"EcoSet x ResNet50-linf8 {layername} ch{unit_i} rep{rep} : Act {Evol_results_eco['scores'][-25:].mean():.2f} time {T2-T1:.2f} sec\")\n",
    "                # plot_evolution_traj(Evol_results_INet)\n",
    "                # plot_evolution_traj(Evol_results_eco)\n",
    "                pkl.dump(Evol_results_INet, open(join(savedir, f\"Evol_results_BigGAN_INet_sigma{init_sigma}_resnet50_linf8_{layername}_ch{unit_i}_rep{rep}.pkl\"), \"wb\"))\n",
    "                # pkl.dump(Evol_results_eco, open(join(savedir, f\"Evol_results_BigGAN_EcoSet_resnet50_linf8_{layername}_ch{unit_i}_rep{rep}.pkl\"), \"wb\"))\n",
    "                print(\"\")\n",
    "        fetcher.cleanup()\n",
    "        del fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
