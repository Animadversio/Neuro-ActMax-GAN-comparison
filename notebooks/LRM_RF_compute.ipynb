{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/harvard-visionlab/lrm-steering/zipball/main\" to /n/holylabs/LABS/kempner_fellows/Users/binxuwang/torch_cache/hub/main.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading weights for alexnet_lrm3, hash_id=63ab1b3b06\n",
      "https://s3.us-east-1.wasabisys.com/visionlab-projects/dnn_feedback_dev/logs/set15/set15_alexnet_torchvision_imagenet1k_lrm_3back_2steps/28453e80-c5e5-4d76-bc81-99c5fade39ff/set15_alexnet_torchvision_imagenet1k_lrm_3back_2steps_final_weights-63ab1b3b06.pth\n",
      "local_filename: /n/holylabs/LABS/kempner_fellows/Users/binxuwang/torch_cache/hub/set15_alexnet_torchvision_imagenet1k_lrm_3back_2steps_final_weights-63ab1b3b06.pth\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model, transforms = torch.hub.load('harvard-visionlab/lrm-steering', 'alexnet_lrm3', pretrained=True, steering=True, force_reload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n",
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToPILImage, ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from pytorch_pretrained_biggan import (BigGAN, truncated_noise_sample, one_hot_from_names, save_as_images)\n",
    "from core.utils.CNN_scorers import TorchScorer\n",
    "from core.utils.GAN_utils import BigGAN_wrapper, upconvGAN, loadBigGAN\n",
    "from core.utils.grad_RF_estim import grad_RF_estimate, gradmap2RF_square\n",
    "from core.utils.layer_hook_utils import get_module_names, layername_dict, register_hook_by_module_names, get_module_name_shapes\n",
    "from core.utils.layer_hook_utils import featureFetcher, featureFetcher_module, featureFetcher_recurrent\n",
    "from core.utils.Optimizers import CholeskyCMAES, HessCMAES, ZOHA_Sphere_lr_euclid\n",
    "from core.utils.Optimizers import label2optimizer\n",
    "\n",
    "\n",
    "def get_center_pos_and_rf(model, layer, input_size=(3, 227, 227), device=\"cuda\"):\n",
    "    module_names, module_types, module_spec = get_module_names(model, input_size=input_size, device=device)\n",
    "    layer_key = [k for k, v in module_names.items() if v == layer][0]\n",
    "    # FIXME note this may not work when multiple layers have the same name.\n",
    "    # This will only get the first one. Need to add a check for this.\n",
    "    feat_outshape = module_spec[layer_key]['outshape']\n",
    "    if len(feat_outshape) == 3:\n",
    "        cent_pos = (feat_outshape[1]//2, feat_outshape[2]//2)\n",
    "    elif len(feat_outshape) == 1:\n",
    "        cent_pos = None\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown layer shape {feat_outshape} for layer {layer}\")\n",
    "\n",
    "    # rf Mapping,\n",
    "    if len(feat_outshape) == 3: # fixit\n",
    "        print(\"Computing RF by direct backprop: \")\n",
    "        gradAmpmap = grad_RF_estimate(model, layer, (slice(None), *cent_pos), input_size=input_size,\n",
    "                                      device=device, show=False, reps=30, batch=1)\n",
    "        Xlim, Ylim = gradmap2RF_square(gradAmpmap, absthresh=1E-8, relthresh=0.01, square=True)\n",
    "        corner = (Xlim[0], Ylim[0])\n",
    "        imgsize = (Xlim[1] - Xlim[0], Ylim[1] - Ylim[0])\n",
    "    elif len(feat_outshape) == 1:\n",
    "        imgsize = input_size[-2:]\n",
    "        corner = (0, 0)\n",
    "        Xlim = (corner[0], corner[0] + imgsize[0])\n",
    "        Ylim = (corner[1], corner[1] + imgsize[1])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown layer shape {feat_outshape} for layer {layer}\")\n",
    "\n",
    "    return cent_pos, corner, imgsize, Xlim, Ylim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layername_map = {\".feedforward.features.Conv2d0\": \"conv1\",\n",
    "\".feedforward.features.ReLU1\": \"conv1_relu\",\n",
    "\".feedforward.features.MaxPool2d2\": \"pool1\",\n",
    "\".feedforward.features.Conv2d3\": \"conv2\",\n",
    "\".feedforward.features.ReLU4\": \"conv2_relu\",\n",
    "\".feedforward.features.MaxPool2d5\": \"pool2\",\n",
    "\".feedforward.features.Conv2d6\": \"conv3\",\n",
    "\".feedforward.features.ReLU7\": \"conv3_relu\",\n",
    "\".feedforward.features.Conv2d8\": \"conv4\",\n",
    "\".feedforward.features.ReLU9\": \"conv4_relu\",\n",
    "\".feedforward.features.Conv2d10\": \"conv5\",\n",
    "\".feedforward.features.ReLU11\": \"conv5_relu\",\n",
    "\".feedforward.features.MaxPool2d12\": \"pool5\",\n",
    "\".feedforward.AdaptiveAvgPool2davgpool\": \"avgpool\",\n",
    "\".feedforward.classifier.Dropout0\": \"avgpool_dropout\",\n",
    "\".feedforward.classifier.Linear1\": \"fc6\",\n",
    "\".feedforward.classifier.ReLU2\": \"fc6_relu\",\n",
    "\".feedforward.classifier.Dropout3\": 'fc6_dropout',\n",
    "\".feedforward.classifier.Linear4\": \"fc7\",\n",
    "\".feedforward.classifier.ReLU5\": \"fc7_relu\",\n",
    "\".feedforward.classifier.Linear6\": \"fc8\",}\n",
    "layername_inv_map = {v: k for k, v in layername_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "      Layer Id       inshape       outshape           Type                 ReadableStr \n",
      "==============================================================================\n",
      "        0        (3, 224, 224) (3, 224, 224)           Input                      Image\n",
      "        1        (3, 224, 224) (64, 55, 55)          Conv2d  .feedforward.features.Conv2d0\n",
      "        2        (64, 55, 55) (64, 55, 55)            ReLU  .feedforward.features.ReLU1\n",
      "        3        (64, 55, 55) (64, 27, 27)       MaxPool2d  .feedforward.features.MaxPool2d2\n",
      "        4        (64, 27, 27) (192, 27, 27)          Conv2d  .feedforward.features.Conv2d3\n",
      "        5        (192, 27, 27) (192, 27, 27)            ReLU  .feedforward.features.ReLU4\n",
      "        6        (192, 27, 27) (192, 13, 13)       MaxPool2d  .feedforward.features.MaxPool2d5\n",
      "        7        (192, 13, 13) (384, 13, 13)          Conv2d  .feedforward.features.Conv2d6\n",
      "        8        (384, 13, 13) (384, 13, 13)            ReLU  .feedforward.features.ReLU7\n",
      "        9        (384, 13, 13) (256, 13, 13)          Conv2d  .feedforward.features.Conv2d8\n",
      "        10       (256, 13, 13) (256, 13, 13)            ReLU  .feedforward.features.ReLU9\n",
      "        11       (256, 13, 13) (256, 13, 13)          Conv2d  .feedforward.features.Conv2d10\n",
      "        12       (256, 13, 13) (256, 13, 13)            ReLU  .feedforward.features.ReLU11\n",
      "        13       (256, 13, 13)  (256, 6, 6)       MaxPool2d  .feedforward.features.MaxPool2d12\n",
      "        14       (3, 224, 224)  (256, 6, 6)      Sequential      .feedforward.features\n",
      "        15        (256, 6, 6)  (256, 6, 6) AdaptiveAvgPool2d  .feedforward.AdaptiveAvgPool2davgpool\n",
      "        16            (9216,)      (9216,)         Dropout  .feedforward.classifier.Dropout0\n",
      "        17            (9216,)      (4096,)          Linear  .feedforward.classifier.Linear1\n",
      "        18            (4096,)      (4096,)            ReLU  .feedforward.classifier.ReLU2\n",
      "        19            (4096,)      (4096,)         Dropout  .feedforward.classifier.Dropout3\n",
      "        20            (4096,)      (4096,)          Linear  .feedforward.classifier.Linear4\n",
      "        21            (4096,)      (4096,)            ReLU  .feedforward.classifier.ReLU5\n",
      "        22            (4096,)      (1000,)          Linear  .feedforward.classifier.Linear6\n",
      "        23            (9216,)      (1000,)      Sequential    .feedforward.classifier\n",
      "        24       (3, 224, 224)      (1000,)         AlexNet        .AlexNetfeedforward\n",
      "        25       (3, 224, 224)      (None,)    SteerableLRM              .SteerableLRM\n",
      "Computing RF by direct backprop: \n",
      "Target setting network alexnet_lrm3 layer .feedforward.features.ReLU4, center pos (13, 13)\n",
      "Xlim (86, 137) Ylim (86, 137) \n",
      " imgsize (51, 51) corner (86, 86)\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict as edict\n",
    "input_size = (3, 224, 224)\n",
    "model.to(\"cuda\")\n",
    "args = edict()\n",
    "args.net = \"alexnet_lrm3\"\n",
    "args.layer = layername_inv_map['conv2_relu'] #\".feedforward.classifier.ReLU2\"\n",
    "model.forward_passes = 1\n",
    "cent_pos, corner, imgsize, Xlim, Ylim = get_center_pos_and_rf(model, args.layer,\n",
    "                                          input_size=input_size, device=\"cuda\")\n",
    "print(\"Target setting network %s layer %s, center pos\" % (args.net, args.layer), cent_pos)\n",
    "print(\"Xlim %s Ylim %s \\n imgsize %s corner %s\" % (Xlim, Ylim, imgsize, corner))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
